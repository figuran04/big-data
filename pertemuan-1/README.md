<!--START_SECTION:medium-->
<h3>Instalasi Anaconda, Praktik Dasar, dan Lanjutan : Instalasi Pyspark dan Pandas - Big Data</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*kFqe2gOPxUev0_Op.png" /></figure><p>Dalam era data yang berkembang pesat ini, kemampuan untuk memproses dan menganalisis data dalam jumlah besar adalah keahlian yang sangat berharga. PySpark dan Pandas adalah dua alat utama yang dapat membantu kita dalam mengelola dan menganalisis data secara efisien. Artikel ini akan memandu Anda melalui langkah-langkah praktis mulai dari instalasi hingga penerapan teknik analisis data dengan PySpark dan Pandas. Kami juga akan menunjukkan bagaimana menggabungkan kekuatan keduanya untuk mencapai hasil yang lebih optimal.</p><p>Setiap langkah dalam panduan ini dilengkapi dengan contoh kode dan praktik langsung, sehingga Anda dapat mengikuti dan menerapkan teknik ini dalam proyek Anda sendiri. Baik Anda seorang pemula yang baru mengenal analisis data maupun seorang profesional yang ingin meningkatkan keterampilan Anda, artikel ini akan memberikan wawasan yang bermanfaat untuk memahami cara kerja PySpark dan Pandas secara mendalam.</p><h4>1. Instalasi Anaconda dan PySpark</h4><p>Untuk memulai dengan PySpark dan Pandas, Anda memerlukan beberapa instalasi dasar:</p><p>Langkah 1: Unduh dan Instal Anaconda.</p><ul><li>Anaconda menyediakan lingkungan yang terintegrasi dengan berbagai alat data science. Unduh dari <a href="https://www.anaconda.com/products/distribution">situs resmi Anaconda</a> dan ikuti petunjuk instalasi.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/780/1*8y1vGe0tNJknLGMef9VsYQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/780/1*v4ephdpPtAIi1wNmqahNLQ.png" /></figure><p>Langkah 2: Pindah ke tab Environments lalu tekan tombol Create.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*_RMfYQpRvjTTJXDPIwykiQ.png" /></figure><p>Langkah 3: Berikan nama environment bebas dan checklist package python usahakan versi sama / kurang dari 3.12 untuk mengikuti seri ini lalu tekan Create.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/750/1*79C3FAYHoLDit2b2711rgA.png" /></figure><h4>2. Pengenalan dan Praktik Dasar PySpark dan Pandas</h4><p>Langkah 1: Membuka Jupyter Notebook</p><ul><li>Jalankan `jupyter notebook` dari terminal Anda untuk membuka lingkungan Jupyter.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*V6xnKZRT5viOe3vYM3KPVQ.png" /></figure><ul><li>Kembali ke tab Environment tekan mouse kiri pada environment yang telah dibuat lalu Open Terminal.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*_DQwHlJ1v0JNEjnEvKtTRg.png" /></figure><ul><li>Instal PySpark, Pandas, Findspark, dan Matplotlib.</li></ul><pre>pip install pyspark==3.4.1<br />pip install pandas<br />pip install findspark<br />pip install matplotlib</pre><ul><li>Satu lagi yaitu instal openjdk dengan mencari melalui pencarian openjdk, checklist package paling bawah dan instal.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*q94C99pgrZpaSULx1AtTYA.png" /></figure><ul><li>Lalu Apply tunggu sampai selesai lalu kembali ke Jupyter Notebook.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/716/1*kLQbE48htDQdujMJzNjgsw.png" /></figure><p>Langkah 2: Membuat Project Notebook Baru</p><ul><li>Buat notebook baru untuk memulai praktik dengan PySpark.</li></ul><p>Langkah 3: Praktik dengan PySpark</p><p>Gunakan kode berikut untuk memulai praktik dengan PySpark:</p><pre>import findspark<br />findspark.init()<br />from pyspark.sql import SparkSession<br /># Memulai Spark session<br />spark = SparkSession.builder.appName("BigDataPractice").getOrCreate()<br /># Membuat DataFrame dengan kolom tambahan<br />data = [<br /> ("Ali", 34, "Dokter", "Membaca", "L"),<br /> ("Budi", 23, "Guru", "Bersepeda", "L"),<br /> ("Citra", 29, "Insinyur", "Menyanyi", "P"),<br /> ("Dina", 45, "Perawat", "Memasak", "P")<br />]<br />columns = ["Nama", "Usia", "Pekerjaan", "Hobi", "Gender"]<br />df = spark.createDataFrame(data, columns)<br /># Menampilkan DataFrame<br />df.show()</pre><h4>3. Praktik PySpark Lanjutan</h4><p>Lakukan manipulasi data menggunakan PySpark dengan kode berikut:</p><pre>from pyspark.sql import SparkSession<br /># Memulai Spark session<br />spark = SparkSession.builder.appName("BigDataPractice").getOrCreate()<br /># Membuat DataFrame sederhana<br />data = [("Ali", 34), ("Budi", 23), ("Citra", 29), ("Dina", 45)]<br />columns = ["Nama", "Usia"]<br />df = spark.createDataFrame(data, columns)<br /># Filtering data (usia > 30)<br />df_filtered = df.filter(df['Usia'] > 30)<br />df_filtered.show()<br /># Menghitung rata-rata usia<br />from pyspark.sql.functions import avg<br />df.groupBy().agg(avg("Usia")).show()<br /># Mengurutkan data berdasarkan usia<br />df_sorted = df.orderBy("Usia", ascending=False)<br />df_sorted.show()</pre><h4>4. Praktik dengan Pandas</h4><p>Gunakan Pandas untuk membuat DataFrame dengan kode berikut:</p><pre>import pandas as pd<br /># Membuat DataFrame Pandas<br />data_pandas = {"Nama": ["Ali", "Budi", "Citra", "Dina"], "Usia": [34, 23, 29, 45]}<br />df_pandas = pd.DataFrame(data_pandas)<br /># Menambahkan kolom baru<br />df_pandas["Pekerjaan"] = ["Dokter", "Guru", "Insinyur", "Perawat"]<br /># Filtering data (usia > 30)<br />df_filtered_pandas = df_pandas[df_pandas['Usia'] > 30]<br /># Menampilkan DataFrame yang telah dimodifikasi<br />df_filtered_pandas</pre><h4>5. Praktik Pandas Lanjutan</h4><p>Lakukan operasi lebih kompleks dengan Pandas:</p><pre>import pandas as pd<br /># Membuat DataFrame pertama<br />data_pandas = {"Nama": ["Ali", "Budi", "Citra", "Dina"], "Usia": [34, 23, 29, 45]}<br />df_pandas = pd.DataFrame(data_pandas)<br /># Membuat DataFrame kedua<br />data_pandas_2 = {"Nama": ["Ali", "Budi", "Citra", "Dina"], "Pekerjaan": ["Dokter", "Guru", "Insinyur", "Perawat"]}<br />df_pandas_2 = pd.DataFrame(data_pandas_2)<br /># Join antara dua DataFrame<br />df_joined = pd.merge(df_pandas, df_pandas_2, on="Nama")<br />print(df_joined)<br /># Menghitung statistik deskriptif<br />print(df_pandas.describe())<br /># Plotting Data<br />import matplotlib.pyplot as plt<br />df_joined['Usia'].plot(kind='bar')<br />plt.show()</pre><h4>6. Menggabungkan PySpark dan Pandas</h4><p>Anda dapat mengonversi DataFrame antara PySpark dan Pandas menggunakan kode berikut:</p><pre>import findspark<br />findspark.init()<br />from pyspark.sql import SparkSession<br />import pandas as pd<br /># Memulai Spark session<br />spark = SparkSession.builder.appName("BigDataPractice").getOrCreate()<br /># Membuat DataFrame PySpark<br />data_spark = [("Ali", 34), ("Budi", 23), ("Citra", 29), ("Dina", 45)]<br />columns_spark = ["Nama", "Usia"]<br />df_spark = spark.createDataFrame(data_spark, columns_spark)<br /># Mengonversi DataFrame dari PySpark ke Pandas<br />df_pandas_from_spark = df_spark.toPandas()<br /># Membuat DataFrame Pandas tambahan<br />data_pandas = {"Nama": ["Ali", "Budi", "Citra", "Dina"], "Pekerjaan": ["Dokter", "Guru", "Insinyur", "Perawat"]}<br />df_pandas = pd.DataFrame(data_pandas)<br /># Menggabungkan DataFrame Pandas dengan DataFrame dari PySpark<br />df_combined = pd.merge(df_pandas_from_spark, df_pandas, on="Nama")<br /># Melakukan analisis sederhana (menghitung rata-rata usia)<br />average_age = df_combined["Usia"].mean()<br />print(f"Rata-rata usia: {average_age}")</pre><h4>7. Konversi Data antara PySpark dan Pandas</h4><pre># Mengonversi DataFrame dari PySpark ke Pandas<br />df_pandas_from_spark = df_spark.toPandas()<br /># Mengonversi DataFrame dari Pandas ke PySpark<br />df_spark_from_pandas = spark.createDataFrame(df_pandas)<br /># Menggabungkan data dari PySpark dan Pandas<br />df_combined_spark = spark.createDataFrame(df_combined)<br /># Operasi statistik (menghitung nilai maksimum usia)<br />max_age = df_combined_spark.agg({"Usia": "max"}).collect()[0][0]<br />print(f"Usia maksimum: {max_age}")</pre><h4>Kesimpulan</h4><p>Melalui panduan ini, kita telah menjelajahi dasar-dasar dan praktik lanjutan dari PySpark dan Pandas, dua alat yang sangat kuat untuk analisis data. Dimulai dengan instalasi dan pengenalan, kita kemudian mendalami berbagai teknik manipulasi data, pengolahan data dalam skala besar, serta visualisasi hasil analisis.</p><p>Dengan menggabungkan PySpark dan Pandas, kita dapat memanfaatkan kekuatan pemrosesan data besar dari PySpark dan fleksibilitas analisis data dari Pandas. Kemampuan untuk mengonversi DataFrame antara kedua alat ini membuka banyak peluang untuk analisis yang lebih komprehensif dan efisien.</p><p>Dengan pengetahuan dan praktik yang telah Anda lakukan, Anda sekarang memiliki fondasi yang kuat untuk memanfaatkan PySpark dan Pandas dalam proyek data Anda. Terus eksplorasi dan kembangkan keterampilan Anda, karena dunia data terus berkembang dan menawarkan tantangan serta peluang baru setiap harinya.</p><h4>Referensi</h4><ul><li><a href="https://docs.anaconda.com/anaconda/install/">Installation - Anaconda documentation</a></li><li><a href="https://drive.google.com/file/d/1vfN58P-SqT4sPMN1AHphCrCjYj1LxTGl/view?usp=sharing">Hands_On_Pertemuan_1.ipynb</a></li></ul><img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=86ab9ce4ea55" width="1" />
<!--END_SECTION:medium-->