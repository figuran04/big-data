<!--START_SECTION:medium-->

[Baca di Medium](https://medium.com/@dikaelsaputra/ekosistem-hadoop-pig-dan-hive-43b48d369828?source=rss-272e0aace4a6------2)

 <h3>Ekosistem Hadoop — Pig dan Hive: Instalasi Hingga Praktik Keduanya</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/737/0*PjA-uKUaZo8q579w.png" /></figure><p>Dalam dunia Big Data, Pig dan Hive adalah dua alat populer yang sering digunakan untuk pemrosesan data di ekosistem Hadoop. Keduanya memiliki kelebihan tersendiri dalam menangani berbagai skenario pemrosesan data. Dalam blog ini, kita akan mempelajari dasar-dasar Pig Latin dan Hive, serta bagaimana menggunakan keduanya dalam tugas-tugas pemrosesan data sederhana.</p><h3>Pengenalan Pig</h3><p>Apache Pig adalah platform tinggi yang digunakan untuk menulis program yang memproses data di Hadoop. Bahasa utama yang digunakan oleh Pig adalah Pig Latin, sebuah bahasa pemrograman tingkat tinggi yang dirancang untuk pemrosesan data besar.</p><h4>Dasar Pig Latin</h4><p>Pig Latin memiliki sintaks yang mirip dengan SQL namun lebih fleksibel dalam hal pemrosesan data non-relasional. Mari kita mulai dengan contoh sederhana untuk memahami sintaks Pig Latin.</p><h4>Contoh Kode Pig Latin Sederhana</h4><pre>students = LOAD 'students.txt' USING PigStorage(',') AS (name:chararray, age:int, gpa:float);<br />filtered_students = FILTER students BY gpa > 3.0;<br />grouped_by_age = GROUP filtered_students BY age;<br />DUMP grouped_by_age;</pre><p>Kode di atas melakukan langkah-langkah berikut:</p><ol><li><strong>LOAD</strong>: Mengambil data dari file students.txt.</li><li><strong>FILTER</strong>: Menyaring siswa yang memiliki GPA lebih dari 3.0.</li><li><strong>GROUP</strong>: Mengelompokkan siswa berdasarkan usia.</li><li><strong>DUMP</strong>: Menampilkan hasil pengelompokan.</li></ol><h3>Pengenalan Hive</h3><p>Apache Hive adalah alat query SQL-like untuk analisis data di Hadoop. Hive memungkinkan pengguna untuk menulis query SQL dan mengeksekusinya pada data yang disimpan di HDFS.</p><h4>Contoh Query Hive Sederhana</h4><p>Sebelum kita mulai dengan query, kita perlu menyiapkan dataset dan membuat tabel di Hive.</p><ul><li><strong>Buat tabel di Hive</strong>:</li></ul><pre>CREATE TABLE students (name STRING, age INT, gpa FLOAT) <br />ROW FORMAT DELIMITED <br />FIELDS TERMINATED BY ',';</pre><ul><li><strong>Import dataset</strong> ke tabel Hive:</li></ul><pre>LOAD DATA INPATH '/user/hive/students.txt' INTO TABLE students;</pre><ul><li><strong>Lakukan query</strong> untuk menyeleksi siswa dengan GPA di atas 3.0:</li></ul><pre>SELECT * FROM students WHERE gpa > 3.0;</pre><h3>Perbandingan Pig dan Hive</h3><p>Meskipun Pig dan Hive memiliki kesamaan dalam hal pemrosesan data di Hadoop, keduanya memiliki karakteristik unik. Berikut adalah komparasi sederhana antara keduanya:</p><a href="https://medium.com/media/1858075638350b5b744001efd4868302/href">https://medium.com/media/1858075638350b5b744001efd4868302/href</a><h3>Instalasi Pig dan Hive di Hadoop</h3><p>Sebelum kita melangkah lebih jauh, mari kita mulai dengan menginstal Apache Pig dan Hive di Hadoop. Pastikan Anda sudah menginstal Hadoop di sistem Anda. Jika belum, Anda bisa mengikuti panduan instalasi Hadoop di Windows yang telah dibahas di blog <a href="https://medium.com/@dikaelsaputra/instalasi-dan-konfigurasi-hadoop-serta-spark-di-windows-f7f3582def93">sebelumnya</a>. Disarankan mengubah versi Java download disini.</p><h3>Langkah-langkah Instalasi Pig</h3><p><strong>Unduh Apache Pig</strong>:</p><ul><li>Unduh versi terbaru <a href="https://dlcdn.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz">Apache Pig</a>.</li></ul><p><strong>Ekstrak file</strong>:</p><ul><li>Ekstrak file Pig yang diunduh ke direktori pilihan Anda.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*e7N_cOW-F8wPUvkTjo5CXg.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*ECvLOo5pTJPbMcEQ8k30xA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*7zAU0dfQHXk3SD1Vi3YxEA.png" /></figure><p><strong>Set PATH untuk Pig</strong>:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/644/1*m3g6g46Wyu740j7sVlwjdw.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*VdQ4Y0kCdcvtBycqm6Egpg.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*fJNkod0X70wVvcCDCi5X2g.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*-hHOjQfSCFMuZCZ6eXT-xQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/824/1*zsNHPKSSMmQXgsRvUHPKKA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/647/1*hkXQNhNv_D2RuUsjpspBMw.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*z-gZwTkLd312ud8lEz6kcg.png" /></figure><p><strong>Verifikasi instalasi Pig</strong>:</p><ul><li>Jalankan perintah berikut untuk memverifikasi instalasi Pig:</li></ul><pre>pig -version</pre><p>Jika Pig berhasil diinstal, Anda akan melihat versi Pig yang terinstal.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*KrvebyABibo91e66r8owug.png" /></figure><h3>Latihan</h3><h4>Masuk ke Mode Local Pig</h4><p>Jalankan perintah berikut di terminal untuk masuk ke mode <strong>local</strong> Pig:</p><pre>pig -x local</pre><p>Mode <strong>local</strong> memungkinkan Pig menjalankan tugas-tugas pemrosesan data di sistem file lokal.</p><h4>Muat Dataset</h4><p>Jalankan perintah berikut untuk memuat dataset students.txt yang terletak di direktori C:/users/user/downloads/. Dataset dimuat menggunakan PigStorage(',') :</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/809/1*XVhCg97c7RQzsoy6FrzYeg.png" /></figure><pre>students = LOAD 'C:/users/user/downloads/students.txt' USING PigStorage(',') AS (name:chararray, age:int, gpa:float);</pre><h4>Filter Data Berdasarkan GPA</h4><p>Gunakan perintah berikut untuk menyaring siswa yang memiliki <strong>GPA lebih dari 3.0</strong>:</p><pre>filtered_students = FILTER students BY gpa > 3.0;</pre><h4>Kelompokkan Berdasarkan Usia</h4><p>Perintah berikut mengelompokkan data siswa yang sudah difilter berdasarkan <strong>usia</strong>:</p><pre>grouped_by_age = GROUP filtered_students BY age;</pre><h4>Tampilkan Hasil</h4><p>Gunakan perintah DUMP untuk menampilkan hasil pengelompokan langsung di terminal:</p><pre>DUMP grouped_by_age;</pre><h4>Output</h4><p>Perintah DUMP akan menampilkan hasil dalam format berikut, di mana data siswa yang memiliki GPA di atas 3.0 dikelompokkan berdasarkan usia mereka:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*lbwyA4-z3gRaS9yqH67gFg.png" /></figure><h3>Pemrosesan Data Sederhana dengan Pig</h3><p>Sekarang, kita akan melakukan analisis sederhana pada dataset menggunakan Pig. Ikuti langkah-langkah berikut:</p><ul><li><strong>Unduh dataset</strong> dari sumber seperti <a href="https://www.kaggle.com">Kaggle</a>. Misalnya, dataset <a href="https://www.kaggle.com/datasets/abdullahashfaqvirk/student-mental-health-survey"><strong>Mental Health Survey</strong></a>.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*hkSQHdL1-D2EIGO-fZZyvg.png" /></figure><ul><li><strong>Impor dataset</strong> ke Hadoop, lalu proses menggunakan Pig dengan menjalankan operasi seperti FILTER, GROUP, dan COUNT.</li></ul><p>Contoh pemrosesan:</p><pre>-- Load dataset<br />data = LOAD 'C:\users\user\downloads\MentalHealthSurvey.csv' <br />       USING PigStorage(',') <br />       AS (<br />           gender:chararray, <br />           age:int, <br />           university:chararray, <br />           degree_level:chararray, <br />           degree_major:chararray, <br />           academic_year:chararray, <br />           cgpa:chararray, <br />           residential_status:chararray, <br />           campus_discrimination:chararray, <br />           sports_engagement:chararray, <br />           average_sleep:chararray, <br />           study_satisfaction:int, <br />           academic_workload:int, <br />           academic_pressure:int, <br />           financial_concerns:int, <br />           social_relationships:int, <br />           depression:int, <br />           anxiety:int, <br />           isolation:int, <br />           future_insecurity:int, <br />           stress_relief_activities:chararray<br />       );<br /><br />-- Memfilter data berdasarkan universitas<br />filtered_data = FILTER data BY university == 'PU';<br /><br />-- Mengelompokkan data berdasarkan gender<br />grouped_data = GROUP filtered_data BY gender;<br /><br />-- Menghitung jumlah data di setiap kelompok<br />counted_data = FOREACH grouped_data GENERATE <br />    group AS gender, <br />    COUNT(filtered_data) AS count;<br /><br />-- Menampilkan hasil<br />DUMP counted_data;</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/739/1*XdREEBK9xK4MwVMBY09gPw.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/739/1*rrFORIqUDpsAX3BepOnd4w.png" /></figure><h3>Langkah-langkah Instalasi Hive</h3><p><strong>Unduh Apache Hive</strong>:</p><ul><li>Unduh versi 3.1.2 <a href="https://archive.apache.org/dist/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz">Apache Hive</a>.</li><li>Unduh <a href="https://archive.apache.org/dist/db/derby/db-derby-10.14.2.0/db-derby-10.14.2.0-bin.zip">Derby 10.14.2.0</a>.</li></ul><p><strong>Ekstrak file Hive</strong>:</p><ul><li>Ekstrak file Hive dan Derby yang diunduh ke direktori pilihan Anda.</li></ul><p><strong>Set PATH untuk Hive</strong>:</p><ul><li>Sama seperti Pig, tambahkan Hive ke PATH. Misalnya:</li></ul><pre>HIVE_HOME=C:\hadoop-3.3.6\hive<br />DERBY_HOME=C:\hadoop-3.3.6\derby<br />HIVE_BIN=C:\hadoop-3.3.6\hive\bin<br />HIVE_LIB=C:\hadoop-3.3.6\hive\lib<br />HADOOP_USER_CLASSPATH_FIRST=true<br />Path=%HIVE_HOME%\bin atau %HIVE_BIN%</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*G2XvQibuEucRx2fY78ypzQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/824/1*_VUcX2XStSuzuKnCJJzedQ.png" /></figure><p><strong>Verifikasi instalasi Hive</strong>:</p><ul><li>Jalankan hadoop terleih dahulu:</li></ul><pre>start-all</pre><ul><li>Jalankan Hive di terminal:</li></ul><pre>hive</pre><p>Jika Hive berhasil diinstal, Anda akan melihat prompt Hive untuk menjalankan query SQL.</p><p>Jika hive tidak ditemukan silahkan pastikan file hive.cmd , cli.cmd , dan execHiveCmd.cmd tersedia. Jika tidak, maka tambahkan manual:</p><p><strong>%HIVE_HOME%\bin\hive.cmd</strong></p><pre>@echo off<br />@rem Licensed to the Apache Software Foundation (ASF) under one or more<br />@rem contributor license agreements.  See the NOTICE file distributed with<br />@rem this work for additional information regarding copyright ownership.<br />@rem The ASF licenses this file to You under the Apache License, Version 2.0<br />@rem (the "License"); you may not use this file except in compliance with<br />@rem the License.  You may obtain a copy of the License at<br />@rem<br />@rem     http://www.apache.org/licenses/LICENSE-2.0<br />@rem<br />@rem Unless required by applicable law or agreed to in writing, software<br />@rem distributed under the License is distributed on an "AS IS" BASIS,<br />@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br />@rem See the License for the specific language governing permissions and<br />@rem limitations under the License.<br />SetLocal EnableDelayedExpansion<br /><br />@rem Set the path<br /><br />if not defined HIVE_BIN_PATH (<br />  set HIVE_BIN_PATH=%~dp0<br />)<br /><br />if "%HIVE_BIN_PATH:~-1%" == "\" (<br />  set HIVE_BIN_PATH=%HIVE_BIN_PATH:~0,-1%<br />)<br /><br />set HIVE_CONFIG_SCRIPT=%HIVE_BIN_PATH%\hive-config.cmd<br /><br />if exist  %HIVE_CONFIG_SCRIPT% (<br />  CALL  %HIVE_CONFIG_SCRIPT% %*<br />)<br /><br />set SERVICE=<br />set HELP=<br />set CATSERVICE=<br />set DEBUG=<br />set CURRENTARG=<br />set HIVEARGS=<br />rem set AUX_CLASSPATH=<br />set AUX_PARAM=<br /><br />@rem parse the command line arguments<br />:ProcessCmdLine<br /> if [%1]==[] goto :FinishArgs<br /><br /> set temp=%1<br /> set temp=%temp:~0, 7%<br /><br /> if %temp%==--debug (<br />  set DEBUG=%*<br />  shift<br />  goto :ProcessCmdLine<br /> )<br /><br /> if %1==--config (<br />  shift<br />  shift<br />  goto :ProcessCmdLine<br /> )<br /><br /> if %1==--auxpath (<br />  shift<br />  shift<br />  goto :ProcessCmdLine<br /> )<br /><br /> if %1==--service (<br />  set SERVICE=%2<br /><br />  if [%3]==[catservicexml] (<br />   set CATSERVICE=_catservice<br />   shift<br />  )<br />  shift<br />  shift<br />  goto :ProcessCmdLine<br /> )<br /><br /> if %1==--rcfilecat (<br />  set SERVICE=rcfilecat<br />  shift<br />  goto :ProcessCmdLine<br /> )<br /><br /> if %1==--orcfiledump (<br />  set SERVICE=orcfiledump<br />  shift<br />  goto :ProcessCmdLine<br /> )<br /><br /> if %1==--help (<br />  set HELP=_help<br />  shift<br />  goto :ProcessCmdLine<br /> )<br /><br /> @rem parameter at %1 does not match any option, these are optional params<br /> goto :FinishArgs<br />:FinishArgs<br /><br />if defined DEBUG (<br /> if defined HELP (<br />  call %HIVE_BIN_PATH%\ext\debug.cmd HELP<br />  goto :EOF<br /> )<br /><br /> call %HIVE_BIN_PATH%\ext\debug.cmd %DEBUG%<br />)<br /><br />if defined HIVE_MAIN_CLIENT_DEBUG_OPTS (<br /> set HADOOP_OPTS=%HADOOP_OPTS% %HADOOP_CLIENT_OPTS% %HIVE_MAIN_CLIENT_DEBUG_OPTS%<br />)<br /><br />if not [%1]==[] (<br /> set CURRENTARG=%1<br /> call :MakeHiveArgs %*<br />)<br /><br />if not defined SERVICE (<br /> if defined HELP (<br />  set SERVICE=help<br /> ) else (<br />  set SERVICE=cli<br /> )<br />)<br /><br />if not defined HIVE_HOME (<br /> echo "HIVE_HOME needs to be defined to point at the root of the hive install"<br /> exit /b 1<br />)<br /><br />if not defined HIVE_CONF_DIR (<br /> set HIVE_CONF_DIR=%HIVE_HOME%\conf<br />)<br /><br />if exist %HIVE_CONF_DIR%/hive-env.cmd CALL %HIVE_CONF_DIR%/hive-env.cmd<br /><br />@rem sort out classpath and make sure dependencies exist<br />set CLASSPATH=%HIVE_CONF_DIR%<br /><br />set HIVE_LIB=%HIVE_HOME%\lib<br /><br />@rem needed for execution<br />if not exist %HIVE_LIB%\hive-exec-*.jar (<br /> echo "Missing Hive Execution Jar: %HIVE_LIB%/hive-exec-*.jar"<br /> exit /b 1<br />)<br /><br />if not exist %HIVE_LIB%\hive-metastore-*.jar (<br /> echo "Missing Hive MetaStore Jar"<br /> exit /b 1<br />)<br /><br />@rem cli specific code<br />if not exist %HIVE_LIB%\hive-cli-*.jar (<br /> echo "Missing Hive CLI Jar"<br /> exit /b 1<br />)<br /><br />set CLASSPATH=%CLASSPATH%;%HIVE_LIB%\*<br /><br />@rem maybe we should just make users set HADOOP_HOME env variable as a prereq<br />@rem in the next iteration, use "where" command to find directory of hadoop install from path<br />if not defined HADOOP_HOME (<br /> echo "HADOOP_HOME needs to be defined to point at the hadoop installation"<br /> exit /b 1<br />)<br /><br />@rem supress the HADOOP_HOME warnings in 1.x.x<br />set HADOOP_HOME_WARN_SUPPRESS=true<br /><br />set HADOOP=%HADOOP_HOME%\bin\hadoop.cmd<br />if not exist %HADOOP% (<br /> echo "Missing hadoop installation: %HADOOP_HOME% must be set"<br /> exit /b 1<br />)<br /><br />@rem can only run against hadoop 1.0.0 as prereq for this iteration - can't figure out the regex/awk script to determine compatibility<br /><br />@rem add auxilary jars such as serdes<br />if not defined HIVE_AUX_JARS_PATH goto :AddAuxLibDir<br /><br />setLocal EnableDelayedExpansion<br />:auxJarLoop<br /> for /f "delims=," %%a in ("!HIVE_AUX_JARS_PATH!") do (<br />  set auxjar=%%a<br />  if exist %%a (<br />   if exist "%%a\nul" (<br />    @rem %%a is a dir<br />    pushd %%a<br />    for /f %%b IN ('dir /b *.jar') do (<br />     set AUX_CLASSPATH=!AUX_CLASSPATH!;%%a\%%b<br />     call :AddToAuxParam %%a\%%b<br />    )<br />    popd<br />   ) else (<br />    @rem %%a is a file<br />    set AUX_CLASSPATH=!AUX_CLASSPATH!;%%a<br />    call :AddToAuxParam %%a<br />   )<br />  )<br /> )<br /> :striploop<br /> set stripchar=!HIVE_AUX_JARS_PATH:~0,1!<br /> set HIVE_AUX_JARS_PATH=!HIVE_AUX_JARS_PATH:~1!<br /> if "!HIVE_AUX_JARS_PATH!" EQU "" goto auxJarLoopEnd<br /> if "!stripchar!" NEQ "," goto striploop<br /> goto auxJarLoop<br /><br />:auxJarLoopEnd<br /><br />if defined HIVE_AUX_JARS_PATH (<br /> echo "setting aux param %HIVE_AUX_JARS_PATH%"<br /> set AUX_CLASSPATH=%HIVE_AUX_JARS_PATH%<br /> set AUX_PARAM=file://%HIVE_AUX_JARS_PATH%<br />)<br /><br /><br />:AddAuxLibDir<br />@rem adding jars from auxlib directory<br />if exist %HIVE_HOME%\auxlib (<br /> pushd %HIVE_HOME%\auxlib<br /> for /f %%a IN ('dir /b *.jar') do (<br />  set AUX_CLASSPATH=%AUX_CLASSPATH%;%%a<br />  call :AddToAuxParam %%a<br /> )<br /> popd<br />)<br /><br />@rem pass classpath to hadoop<br />set HADOOP_CLASSPATH=%HADOOP_CLASSPATH%;%CLASSPATH%;%AUX_CLASSPATH%<br /><br />@rem also pass hive classpath to hadoop<br />if defined HIVE_CLASSPATH (<br />  set HADOOP_CLASSPATH=%HADOOP_CLASSPATH%;%HIVE_CLASSPATH%<br />)<br /><br />@rem set hbase components<br />if defined HBASE_HOME (<br />  if not defined HBASE_CONF_DIR (<br />    if exist %HBASE_HOME%\conf (<br />      set HBASE_CONF_DIR=%HBASE_HOME%\conf<br />    )<br />  )<br />  if defined HBASE_CONF_DIR (<br />    call :AddToHadoopClassPath %HBASE_CONF_DIR% <br />  ) <br />  if exist %HBASE_HOME%\lib (<br />    call :AddToHadoopClassPath %HBASE_HOME%\lib\*<br />  ) <br />)<br /><br />if defined AUX_PARAM (<br />        set HIVE_OPTS=%HIVE_OPTS% -hiveconf hive.aux.jars.path="%AUX_PARAM%"<br /> set AUX_JARS_CMD_LINE="-libjars %AUX_PARAM%"<br />)<br /><br />@rem Get ready to run the services<br />set SERVICE_COUNT=0<br />set TORUN=""<br />call :AddServices<br />For /L %%i in (1,1,%SERVICE_COUNT%) do (<br /> if "%SERVICE%" == "!VAR%%i!" (<br />  set TORUN=!VAR%%i!<br /> )<br />)<br /><br />if %TORUN% == "" (<br /> echo "Service %SERVICE% not available"<br /> exit /b 1<br />)<br /><br /><br />if defined HELP (<br /> call %HIVE_BIN_PATH%\ext\%TORUN%.cmd %TORUN%%HELP% %*<br /> goto :EOF<br />)<br /><br />@rem generate xml for the service, also append hadoop dependencies to the classpath<br />if defined CATSERVICE (<br />  if exist  %HADOOP_HOME%\libexec\hadoop-config.cmd (<br />   call %HADOOP_HOME%\libexec\hadoop-config.cmd<br /> ) else (<br />   call %HADOOP_HOME%\libexec\hadoop-config.cmd<br /> )<br /> call %HIVE_BIN_PATH%\ext\%TORUN%.cmd %TORUN%%CATSERVICE% %*<br /> goto :EOF<br />)<br /><br />call %HIVE_BIN_PATH%\ext\%TORUN%.cmd %TORUN% %*<br /><br /><br /><br />goto :EOF<br />@rem done body of script<br /><br /><br />@rem start utility functions here<br /><br />@rem strip off preceding arguments like --service so that subsequent args can be passed on<br />:MakeHiveArgs<br /> set _count=0<br /> set _shift=1<br /> set HIVEARGS=<br /><br /> if not defined CURRENTARG (<br />  goto :EndLoop<br /> )<br /> :HiveArgsLoop<br />  if [%1]==[] (<br />   goto :EndLoop<br />  )<br />  if not %1==%CURRENTARG% (<br />   shift<br />   goto :HiveArgsLoop<br />  )<br /><br />  if not defined HIVEARGS (<br />   set HIVEARGS=%1<br />  ) else (<br />   set HIVEARGS=%HIVEARGS% %1<br />  )<br />  shift<br />  set CURRENTARG=%1<br />  goto :HiveArgsLoop<br /> :EndLoop<br />goto :EOF<br /><br />@rem makes list of available services<br />:AddServices<br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=cli<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=help<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=hiveserver<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=hiveserver2<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=hwi<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=jar<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=lineage<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=metastore<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=rcfilecat<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=orcfiledump<br /><br /> set /a SERVICE_COUNT = %SERVICE_COUNT% + 1<br /> set VAR%SERVICE_COUNT%=schematool<br />goto :EOF<br /><br />:AddToAuxParam<br />if not defined AUX_PARAM (<br /> set AUX_PARAM=file:///%1<br /> ) else (<br /> set AUX_PARAM=%AUX_PARAM%,file:///%1<br /> )<br />)<br />goto :EOF<br /><br />:AddToHadoopClassPath<br />if defined HADOOP_CLASSPATH (<br />  set HADOOP_CLASSPATH=%HADOOP_CLASSPATH%;%1<br />) else (<br />    set HADOOP_CLASSPATH=%1<br />  )  <br />)<br />goto :EOF</pre><p><strong>%HIVE_HOME%\bin\ext\cli.cmd</strong></p><pre>@echo off<br />@rem Licensed to the Apache Software Foundation (ASF) under one or more<br />@rem contributor license agreements.  See the NOTICE file distributed with<br />@rem this work for additional information regarding copyright ownership.<br />@rem The ASF licenses this file to You under the Apache License, Version 2.0<br />@rem (the "License"); you may not use this file except in compliance with<br />@rem the License.  You may obtain a copy of the License at<br />@rem<br />@rem     http://www.apache.org/licenses/LICENSE-2.0<br />@rem<br />@rem Unless required by applicable law or agreed to in writing, software<br />@rem distributed under the License is distributed on an "AS IS" BASIS,<br />@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br />@rem See the License for the specific language governing permissions and<br />@rem limitations under the License.<br /><br />set CLASS=org.apache.hadoop.hive.cli.CliDriver<br />pushd %HIVE_LIB%<br />for /f %%a IN ('dir /b hive-cli-*.jar') do (<br /> set JAR=%HIVE_LIB%\%%a<br />)<br />popd<br /><br />if [%1]==[cli_help] goto :cli_help<br /><br />:cli<br /> call %HIVE_BIN_PATH%\ext\util\execHiveCmd.cmd %CLASS%<br />goto :EOF<br /><br />:cli_help<br /> set HIVEARGS=--help<br /> call :cli<br />goto :EOF</pre><p><strong>%HIVE_HOME%\bin\ext\util\execHiveCmd.cmd</strong></p><pre>@echo off<br />@rem Licensed to the Apache Software Foundation (ASF) under one or more<br />@rem contributor license agreements.  See the NOTICE file distributed with<br />@rem this work for additional information regarding copyright ownership.<br />@rem The ASF licenses this file to You under the Apache License, Version 2.0<br />@rem (the "License"); you may not use this file except in compliance with<br />@rem the License.  You may obtain a copy of the License at<br />@rem<br />@rem     http://www.apache.org/licenses/LICENSE-2.0<br />@rem<br />@rem Unless required by applicable law or agreed to in writing, software<br />@rem distributed under the License is distributed on an "AS IS" BASIS,<br />@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br />@rem See the License for the specific language governing permissions and<br />@rem limitations under the License.<br /><br />if [%1]==[] (<br /> echo "No class set to run.  Please specify the class to run."<br /> exit /b 1<br />)<br />set CLASS=%1<br />@rem hadoop 20 or newer - skip the aux_jars option. picked up from hiveconf<br />call %HADOOP% jar %JAR% %CLASS% %HIVE_OPTS% %HIVEARGS%<br />goto :EOFcd %HIVE_HOME%\bin</pre><p><strong>%HIVE_HOME%\bin\conf\hive-site.xml</strong></p><pre><?xml version="1.0"?><br /><?xml-stylesheet type=”text/xsl” href=”configuration.xsl”?><br /><configuration><property> <name>javax.jdo.option.ConnectionURL</name><br /><value>jdbc:derby://localhost:1527/metastore_db;create=true</value><br /><description>JDBC connect string for a JDBC metastore</description><br /></property><property><br /><name>javax.jdo.option.ConnectionDriverName</name><br /><value>org.apache.derby.jdbc.ClientDriver</value><br /><description>Driver class name for a JDBC metastore</description><br /></property><br /><property><br /><name>hive.server2.enable.doAs</name><br /><description>Enable user impersonation for HiveServer2</description><br /><value>true</value><br /></property><br /><property><br /><name>hive.server2.authentication</name><br /><value>NONE</value><br /><description> Client authentication types. NONE: no authentication check LDAP: LDAP/AD based authentication KERBEROS: Kerberos/GSSAPI authentication CUSTOM: Custom authentication provider (Use with property hive.server2.custom.authentication.class) </description><br /></property><br /><property><br /><name>datanucleus.autoCreateTables</name><br /><value>True</value><br /></property><br /><property><br /><name>hive.server2.active.passive.ha.enable</name><br /><value>true</value><br /></property><br /></configuration></pre><p>Pindahkan beberapa librari dari %DERBY_HOME%\lib ke %HIVE_HOME%\hive\lib :</p><p><strong>Jalankan</strong> kembali hive pastikan haddop menyala start-all.</p><pre>cd %HIVE_HOME%\bin<br />hive</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*X-eiPmyTIWlzO7L1sy2xsA.png" /></figure><p>Jika masih gagal silahkan cek versi guava-27.0-jre.jar pada %HIVE_HOME%\hive\lib dan %HADOOP_HOME%\share\hadoop\common\lib disamakan dengan cara <strong>singkirkan</strong> versi lama <strong>tempel</strong> versi baru.</p><p><strong>PERHATIAN: </strong>Selalu buka command promt dengan <strong>Run As Administrator </strong>dan ketika selesai konfigurasi harap <strong>buka cmd baru</strong>.</p><h3>Pemrosesan Data dengan Hive</h3><p>Setelah tabel dibuat dan data diimpor ke Hive, kita bisa menjalankan berbagai query untuk memanipulasi dan menganalisis data. Contohnya:</p><ul><li><strong>JOIN</strong>: Menggabungkan dua tabel.</li><li><strong>GROUP BY</strong>: Mengelompokkan data.</li><li><strong>SELECT</strong>: Menyeleksi data berdasarkan kondisi tertentu.</li></ul><p>Contoh:</p><pre>SELECT age, COUNT(*) <br />FROM students <br />GROUP BY age;</pre><p><strong><em>Kapan Menggunakan Pig?</em></strong></p><ul><li>Pig lebih cocok digunakan untuk tugas-tugas yang memerlukan fleksibilitas dalam pemrosesan data non-relasional atau semi-terstruktur. Pig Latin memiliki sintaks yang lebih ekspresif dan mendukung tugas pemrosesan data yang kompleks dengan efisiensi tinggi.</li></ul><p><strong><em>Kapan Menggunakan Hive?</em></strong></p><ul><li>Hive ideal untuk pengguna yang lebih familiar dengan SQL dan memerlukan alat untuk melakukan query dan analisis data terstruktur yang disimpan di HDFS. Hive lebih mudah diakses bagi pengguna bisnis atau data analyst yang terbiasa dengan SQL.</li></ul><h3>Kesimpulan</h3><p>Pig dan Hive adalah dua alat yang penting dalam ekosistem Hadoop, masing-masing dengan kekuatan dan kelemahan tersendiri. Pig menawarkan fleksibilitas dan efisiensi dalam pemrosesan data, sementara Hive memudahkan analisis data menggunakan sintaks SQL yang familiar. Pilihan antara Pig atau Hive bergantung pada kebutuhan spesifik dan kompleksitas tugas yang dihadapi.</p><h3>Referensi</h3><p><a href="https://stackoverflow.com/questions/42958213/install-hive-on-windows-hive-is-not-recognized-as-an-internal-or-external-com">Install Hive on windows: 'hive' is not recognized as an internal or external command, operable program or batch file</a></p><img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=43b48d369828" width="1" />
<!--END_SECTION:medium-->
