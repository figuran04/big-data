<!--START_SECTION:medium-->
<h3>Instalasi dan Konfigurasi Hadoop serta Spark di Windows: Instalasi JDK Hingga Integrasi Hadoop dengan Spark</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/700/0*N4ybCsS4TUFsX5sU.jpg" /></figure><p>Hadoop dan Spark adalah dua komponen penting dalam dunia Big Data. Hadoop bertanggung jawab untuk penyimpanan dan pemrosesan data dalam skala besar, sementara Spark menawarkan kerangka kerja yang cepat dan mudah digunakan untuk analisis data. Bagi mereka yang ingin mulai bekerja dengan Big Data, menguasai instalasi dan konfigurasi Hadoop serta Spark di Windows adalah langkah awal yang krusial. Beberapa poin penting sbagai berikut:</p><ol><li><strong>Hadoop Distributed File System (HDFS):</strong> HDFS adalah sistem file terdistribusi yang memungkinkan penyimpanan data dalam skala besar di banyak mesin, sehingga memastikan redundansi dan ketersediaan tinggi.</li><li><strong>Spark:</strong> Spark dikenal dengan kecepatan dan kemampuannya untuk memproses data dalam memori, yang membuatnya jauh lebih cepat dibandingkan MapReduce tradisional di Hadoop.</li><li><strong>Winutils:</strong> Dalam lingkungan Windows, winutils.exe sangat penting agar Hadoop dapat berjalan dengan benar karena beberapa fungsi Hadoop memerlukan utilitas ini.</li><li><strong>Konfigurasi yang Tepat:</strong> Kesuksesan dalam instalasi dan konfigurasi sangat bergantung pada penyesuaian environment variables dan file konfigurasi Hadoop agar sesuai dengan sistem operasi dan arsitektur jaringan.</li></ol><h4>Langkah 1: Instalasi JDK (Java Development Kit)</h4><ul><li><strong>Unduh JDK</strong> dari <a href="https://www.oracle.com/java/technologies/downloads/">Oracle</a>.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*BuIwvRc8NeYJMAFQ_GoLCw.png" /><figcaption>Gambar 1 Tampilan halaman unduh JDK dari Oracle.</figcaption></figure><ul><li><strong>Instal JDK</strong> dan ekstrak ke direktori C:\Java\jdk-22\.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*PA1w2cN_8bSuS79ui_WlBg.png" /><figcaption>Gambar 2.1 Proses instalasi JDK dan direktori tujuan.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/781/1*On9wj99O06kCe40r7RtjbA.png" /><figcaption>Gambar 2.2 Proses instalasi JDK dan direktori tujuan.</figcaption></figure><ul><li><strong>Verifikasi instalasi</strong> dengan membuka CMD dan ketik perintah berikut:</li></ul><pre>java -version<br />javac -version</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/739/1*81BbviUmrHWnsaOBTdrJZA.png" /><figcaption>Gambar 3 CMD menunjukkan versi Java yang terinstal.</figcaption></figure><h4>Langkah 2: Instalasi Hadoop</h4><ul><li><strong>Unduh Hadoop</strong> dari <a href="https://hadoop.apache.org/releases.html">Apache Hadoop</a> (versi terbaru saat artikel ini dibuat: 3.4.0).</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*M9fUexmsbzS0pLirJBKUOg.png" /><figcaption>Gambar 4 Tampilan halaman unduh Hadoop.</figcaption></figure><ul><li><strong>Ekstrak Hadoop</strong> ke direktori C:\Hadoop\hadoop-3.4.0.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*reV4Ikzbz9TFEtGEixGp7A.png" /><figcaption>Gambar 5.1 Proses ekstraksi Hadoop ke direktori.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*7ZhF5TrBxm4YFfF1kizICw.png" /><figcaption>Gambar 5.2 Proses ekstraksi Hadoop ke direktori.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*UL-x1-_OHNei3Lux2YxSSg.png" /><figcaption>Gambar 5.3 Proses ekstraksi Hadoop ke direktori.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*hqS69tefKjMsKFEbopk1EQ.png" /><figcaption>Gambar 5.4 Proses ekstraksi Hadoop ke direktori.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/683/1*nnfctxd_4_M_p5lYig5Lrg.png" /><figcaption>Gambar 5.5 Proses ekstraksi Hadoop ke direktori.</figcaption></figure><ul><li><strong>Unduh winutils</strong> dari <a href="https://github.com/kontext-tech/winutils/tree/master/hadoop-3.4.0-win10-x64">Kontext Tech GitHub</a> Anda dapat menyalin url berikut https://github.com/kontext-tech/winutils/tree/master/hadoop-3.4.0-win10-x64 lalu akses website <a href="https://download-directory.github.io">Download Directory Github</a>, tempel url tersebut tunggu hingga muncul pop up unduh lalu unduh.</li></ul><p><strong><em>Kenapa winutils diperlukan?</em></strong></p><p>Winutils diperlukan agar Hadoop bisa berjalan di lingkungan Windows karena beberapa fitur Hadoop memerlukan akses ke utilitas spesifik Windows.</p><ul><li><strong>Ekstrak winutils</strong> dan salin ke direktori C:\Hadoop\hadoop-3.4.0\bin cara seperti di atas yaitu atau extrak biasa.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*rMS0-dBGosAzMgNEqIZY_g.png" /><figcaption>Gambar 6.1 Proses penyalinan winutils ke folder bin Hadoop.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/702/1*5r1sFOPs6rVdH3u65TamIA.png" /><figcaption>Gambar 6.2 Proses penyalinan winutils ke folder bin Hadoop.</figcaption></figure><h4>Langkah 3: Instalasi Spark</h4><ul><li><strong>Unduh Spark</strong> dari <a href="https://www.apache.org/dyn/closer.lua/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz">Apache Spark</a>.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*t4-SQPjwTuRPaP2ttGpqfw.png" /><figcaption>Gambar 7 Tampilan halaman unduh Spark.</figcaption></figure><ul><li><strong>Ekstrak Spark</strong> ke direktori C:\Spark\spark-3.5.2-bin-hadoop3 cara seperti pada Hadoop untuk menghindari terjadinya error maupun corrupt.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*tni3qi_LORQk4bPMOaBQVg.png" /><figcaption>Gambar 8 Proses ekstraksi Spark ke direktori tujuan.</figcaption></figure><h4>Langkah 4: Konfigurasi Hadoop</h4><ul><li><strong>Edit file </strong>core-site.xml di C:\Hadoop\hadoop-3.4.0\etc\hadoop\:</li></ul><pre><configuration><br />  <property><br />    <name>fs.defaultFS</name><br />    <value>hdfs://localhost:9000</value><br />  </property><br /></configuration></pre><ul><li><strong>Edit file </strong>hdfs-site.xml:</li></ul><pre><configuration><br />  <property><br />    <name>dfs.replication</name><br />    <value>1</value><br />  </property><br />  <property><br />    <name>dfs.namenode.name.dir</name><br />    <value>file:///C:/Hadoop/hadoop-3.4.0/namenode</value><br />  </property><br />  <property><br />    <name>dfs.datanode.data.dir</name><br />    <value>file:///C:/Hadoop/hadoop-3.4.0/datanode</value><br />  </property><br /></configuration></pre><ul><li><strong>Edit file </strong>mapred-site.xml:</li></ul><pre><configuration><br />  <property><br />    <name>mapreduce.framework.name</name><br />    <value>yarn</value><br />  </property><br /></configuration></pre><ul><li><strong>Edit file </strong>yarn-site.xml:</li></ul><pre><configuration><br />  <property><br />    <name>yarn.nodemanager.aux-services</name><br />    <value>mapreduce_shuffle</value><br />  </property><br />  <property><br />    <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name><br />    <value>org.apache.hadoop.mapred.ShuffleHandler</value><br />  </property><br /></configuration></pre><ul><li><strong>Buat dua folder</strong> bernama namenode dan datanode di C:\Hadoop\hadoop-3.4.0\.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*V1MhOMUEzhQqRz4PxUTCkg.png" /><figcaption>Gambar 9 Struktur folder dengan namenode dan datanode.</figcaption></figure><h4>Langkah 5: Setup Environment Variables</h4><ul><li><strong>Tambahkan variabel environment</strong> berikut:</li></ul><pre>HADOOP_HOME: C:\Hadoop\hadoop-3.4.0<br />JAVA_HOME: C:\Java\jdk-22<br />HADOOP_CONF_FILE: C:\Hadoop\hadoop-3.4.0\etc\hadoop<br />SPARK_HOME: C:\Spark\spark-3.5.2-bin-hadoop3</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*38MncuI47NsC679CVt7HpA.png" /><figcaption>Gambar 10.1 Tampilan konfigurasi environment variables di Windows.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/644/1*9e-2pYrwr7QltnrmXgeVew.png" /><figcaption>Gambar 10.2 Tampilan konfigurasi environment variables di Windows.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*F9uULwWq1BemywVSSRDl0w.png" /><figcaption>Gambar 10.3 Tampilan konfigurasi environment variables di Windows.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*yx97bbU8oVTGtl95sj2dqw.png" /><figcaption>Gambar 10.4 Tampilan konfigurasi environment variables di Windows.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*_N9f6VpmeSawJ-va48RUZw.png" /><figcaption>Gambar 10.5 Tampilan konfigurasi environment variables di Windows.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*KeqOd1hkl-TSI-nIkoxMfg.png" /><figcaption>Gambar 10.6 Tampilan konfigurasi environment variables di Windows.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*vPsT7hoVQ7AugZTQ9VtUcQ.png" /><figcaption>Gambar 10.7 Tampilan konfigurasi environment variables di Windows.</figcaption></figure><ul><li><strong>Edit Path</strong>:</li></ul><pre>%JAVA_HOME%\bin<br />%HADOOP_HOME%\bin<br />%HADOOP_HOME%\sbin<br />%SPARK_HOME%\bin</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*va9ophKWGuzIIDuyhxqabg.png" /><figcaption>Gambar 11.1 Tampilan pengaturan Path di environment variables.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/824/1*SpJVTo0tH_qNS5sQnQSZOg.png" /><figcaption>Gambar 11.2 Tampilan pengaturan Path di environment variables.</figcaption></figure><h4>Langkah 6: Verifikasi Instalasi</h4><ul><li><strong>Verifikasi Hadoop</strong> dengan perintah berikut di CMD:</li></ul><pre>hadoop version</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*26D7ELHaCVhA3o-sdl0K6w.png" /><figcaption>Gambar 12 CMD menunjukkan versi Hadoop yang terinstal.</figcaption></figure><ul><li><strong>Format HDFS</strong>:</li></ul><pre>hdfs namenode -format</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*wzANvxg6vNGg9o1P1iEv4g.png" /><figcaption>Gambar 13 Proses format HDFS di CMD.</figcaption></figure><ul><li><strong>Jalankan Hadoop</strong>:</li></ul><pre>start-dfs.sh</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/739/1*zrTSUp-Fgyl_L9yp9MQizw.png" /><figcaption>Gambar 14.1 CMD yang menunjukkan proses startup Hadoop.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/739/1*lBlyQRjMeRVFei0mnAkwtw.png" /><figcaption>Gambar 14.2 CMD yang menunjukkan proses startup Hadoop namenode.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/739/1*4T-sUtUjEAzkLWtNU5yASA.png" /><figcaption>Gambar 14.3 CMD yang menunjukkan proses startup Hadoop datanode.</figcaption></figure><ul><li><strong>Cek proses yang berjalan</strong>:</li></ul><pre>jps</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/739/1*zeiJnKNWd5n6t28Ata2sfA.png" /><figcaption>Gambar 15 CMD jps.</figcaption></figure><p><strong><em>Mengapa proses </em></strong><strong><em>jps, </em></strong><strong><em>namenode, dan </em></strong><strong><em>datanode penting untuk muncul?</em></strong></p><p>jps menunjukkan daftar proses Java yang berjalan, termasuk namenode dan datanode. Jika salah satu tidak muncul, berarti ada masalah dalam konfigurasi atau startup.</p><ul><li><strong>Cek </strong><strong>http://localhost:9870/dfshealth.html:</strong></li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*oNPhWq0WtUuIyy6AEEFRfQ.png" /><figcaption>Gambar 16 Tampilan Hadoop overview.</figcaption></figure><h4>Langkah 7: Struktur dan Operasi Dasar HDFS</h4><ul><li><strong>Membuat direktori dan mengunggah file</strong>:</li></ul><pre>hdfs dfs -mkdir /user/users/<br />echo "hello" > input.txt<br />hdfs dfs -put input.txt /user/users/<br />hdfs dfs -ls /user/users/</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*NTDXWwm2cIyWN_Fg-7MJYw.png" /><figcaption>Gambar 17 CMD menunjukkan perintah dan output untuk membuat direktori dan mengunggah file ke HDFS.</figcaption></figure><ul><li><strong>Operasi File di HDFS</strong>:</li></ul><pre>hdfs dfs -cat /user/users/input.txt<br />hdfs dfs -cp /user/users/input.txt /user/users/input_copy.txt<br />hdfs dfs -ls /user/users/<br />hdfs dfs -rm /user/users/input_copy.txt<br />hdfs dfs -ls /user/users/</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*Z8Bpaw6Fav48b0o1ilDH_w.png" /><figcaption>Gambar 18 CMD menunjukkan operasi file seperti cat, cp, rm di HDFS.</figcaption></figure><ul><li><strong>Menganalisis Struktur Penyimpanan di HDFS:</strong></li></ul><pre>hdfs dfsadmin -report      <br />hdfs fsck / -files -blocks -locations</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*xuDl921bQw9CW8dEWGoLcQ.png" /><figcaption>Gambar 19.1 CMD menunjukkan perintah menganalisis struktur penyimpanan di HDFS.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*v-JPzDDFt73lKgqk8m_BdQ.png" /><figcaption>Gambar 19.2 CMD menunjukkan perintah menganalisis struktur penyimpanan di HDFS.</figcaption></figure><h4>Langkah 8: Integrasi Hadoop dengan Spark</h4><ul><li><strong>Jalankan Spark</strong>:</li></ul><pre>spark-shell</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*6rl3sNSaubyGeX1ZqH9DoQ.png" /><figcaption>Gambar 20Tampilan CMD menunjukkan startup spark-shell.</figcaption></figure><ul><li><strong>Contoh penggunaan Spark untuk membaca file dari HDFS</strong>:</li></ul><pre>val data = sc.textFile("hdfs://localhost:9000/user/users/input.txt").map(line => new String(line.getBytes, "UTF-8"))<br />val line = data.first()<br />val charCount = line.length<br />println(s"The number of characters in the word is: $charCount")</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/827/1*jvd1f9zXsI6_vvr3beT4_g.png" /><figcaption>Gambar 21 Hasil dari kode Spark di spark-shell.</figcaption></figure><p><strong><em>Apa yang dilakukan perintah di atas?</em></strong></p><p>Perintah tersebut membaca file dari HDFS, mengubah encoding, dan menghitung jumlah karakter di baris pertama.</p><h4>Contoh Kasus dan Penyelesaiannya</h4><p><strong><em>Hanya jps yang muncul saat menjalankan jps setelah start-dfs?</em></strong></p><ul><li>Cek apakah winutils.exe sudah ada di C:\Hadoop\hadoop-3.4.0\bin. Jika tidak, pastikan telah mengunduh dan menyalinnya ke direktori yang benar.</li></ul><p><strong><em>Hanya jps dan salah satu antara namenode dan datanode yang muncul?</em></strong></p><ul><li>Tutup kedua cmd tersebut lalu masuk ke C:\Hadoop\hadoop-3.4.0\ hapus yang ada di dalam datanode dan namenode lalu format ulang hdfs namenode -format dan jalankan kembali start-dfs.sh.</li></ul><p><strong><em>Gagal memformat HDFS dengan pesan kesalahan “Could not locate executable winutils.exe”?</em></strong></p><ul><li>Pastikan HADOOP_HOME dan Path sudah terkonfigurasi dengan benar. Jika masalah berlanjut, pastikan file winutils.exe ada di direktori bin.</li></ul><p><strong><em>Spark tidak bisa membaca file dari HDFS?</em></strong></p><ul><li>Periksa kembali alamat file di HDFS dan pastikan Hadoop sedang berjalan dengan benar.</li></ul><h4>Kesimpulan</h4><p>Dengan mengikuti langkah-langkah di atas, Anda telah berhasil menginstal dan mengonfigurasi Hadoop serta Spark di Windows. Jika terjadi masalah, periksa konfigurasi file dan environment variables Anda. Eksperimenlah dengan berbagai pengaturan dan jangan ragu untuk menyesuaikan setup ini sesuai kebutuhan. Jika ada pertanyaan atau masalah lain, silakan tinggalkan komentar!</p><h4>Referensi</h4><ul><li><a href="https://github.com/kontext-tech/winutils/tree/master/hadoop-3.4.0-win10-x64">winutils/hadoop-3.4.0-win10-x64 at master · kontext-tech/winutils</a></li><li><a href="https://maiaphrodite.medium.com/menginstall-apache-hadoop-dan-apache-spark-d22e458357ea">Menginstall Apache Hadoop dan Apache Spark</a></li></ul><img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f7f3582def93" width="1" />
<!--END_SECTION:medium-->