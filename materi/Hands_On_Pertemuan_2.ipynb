{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac766966",
   "metadata": {},
   "source": [
    "# Hands-On Pertemuan 2: Instalasi dan Konfigurasi Hadoop serta Struktur HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c2d52",
   "metadata": {},
   "source": [
    "## Tujuan:\n",
    "- Memahami langkah-langkah instalasi dan konfigurasi Hadoop.\n",
    "- Mempraktikkan bagaimana menggunakan Hadoop dan memahami struktur HDFS.\n",
    "- Mengeksplorasi command line interface (CLI) Hadoop dan melakukan operasi dasar pada HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7a499",
   "metadata": {},
   "source": [
    "### 1. Instalasi Hadoop di Mode Standalone\n",
    "1. **Unduh Hadoop**: Kunjungi [Apache Hadoop](https://hadoop.apache.org/releases.html) untuk mengunduh versi terbaru.\n",
    "2. **Ekstrak dan Setup**: Tambahkan Hadoop ke dalam `$PATH` dan konfigurasi environment variable.\n",
    "   ```bash\n",
    "   export HADOOP_HOME=/path/to/hadoop\n",
    "   export PATH=$PATH:$HADOOP_HOME/bin\n",
    "   export JAVA_HOME=/path/to/java\n",
    "   ```\n",
    "3. **Format HDFS**: Format Hadoop file system dengan:\n",
    "   ```bash\n",
    "   hdfs namenode -format\n",
    "   ```\n",
    "4. **Start Hadoop**: Jalankan Hadoop dengan perintah:\n",
    "   ```bash\n",
    "   start-dfs.sh\n",
    "   ```\n",
    "- **Tugas 1**: Format HDFS dan jalankan dalam mode standalone. Verifikasi dengan menjalankan perintah `hadoop version`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c5ffee",
   "metadata": {},
   "source": [
    "### 2. Struktur HDFS dan Operasi Dasar\n",
    "HDFS merupakan file system terdistribusi yang memungkinkan penyimpanan dan pemrosesan data besar secara paralel.\n",
    "- **Operasi Dasar HDFS**:\n",
    "   - Buat direktori baru di HDFS:\n",
    "   ```bash\n",
    "   hdfs dfs -mkdir /user/student\n",
    "   ```\n",
    "   - Unggah file ke HDFS:\n",
    "   ```bash\n",
    "   hdfs dfs -put input.txt /user/student/\n",
    "   ```\n",
    "   - Tampilkan file yang telah diunggah:\n",
    "   ```bash\n",
    "   hdfs dfs -ls /user/student/\n",
    "   ```\n",
    "- **Tugas 2**: Buat direktori di HDFS, upload file teks, tampilkan konten file, dan hapus file tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f155c9b",
   "metadata": {},
   "source": [
    "### 3. Operasi File di HDFS\n",
    "Lakukan operasi pada file yang telah diunggah:\n",
    "1. **Melihat Konten File**:\n",
    "   ```bash\n",
    "   hdfs dfs -cat /user/student/input.txt\n",
    "   ```\n",
    "2. **Menduplikasi File**:\n",
    "   ```bash\n",
    "   hdfs dfs -cp /user/student/input.txt /user/student/input_copy.txt\n",
    "   ```\n",
    "3. **Menghapus File dari HDFS**:\n",
    "   ```bash\n",
    "   hdfs dfs -rm /user/student/input_copy.txt\n",
    "   ```\n",
    "- **Tugas 3**: Lakukan operasi untuk menampilkan konten file, menduplikasi, dan menghapus file di HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c979e38",
   "metadata": {},
   "source": [
    "### 4. Menganalisis Struktur Penyimpanan di HDFS\n",
    "Untuk memahami bagaimana HDFS mengelola penyimpanan, gunakan perintah berikut:\n",
    "- **Menampilkan informasi penyimpanan HDFS**:\n",
    "   ```bash\n",
    "   hdfs dfsadmin -report\n",
    "   ```\n",
    "- **Menampilkan status block**:\n",
    "   ```bash\n",
    "   hdfs fsck / -files -blocks -locations\n",
    "   ```\n",
    "- **Tugas 4**: Lakukan analisis pada struktur penyimpanan di HDFS dan tuliskan laporan berdasarkan hasil dari `hdfs dfsadmin -report`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e5ca0",
   "metadata": {},
   "source": [
    "### 5. Tugas Tambahan: Integrasi Hadoop dengan Spark\n",
    "- Coba instal Spark dan konfigurasi dengan Hadoop. Lakukan operasi sederhana untuk memproses data menggunakan Spark yang tersimpan di HDFS."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
